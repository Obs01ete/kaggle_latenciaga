{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.009203,
     "end_time": "2023-09-01T16:50:47.024469",
     "exception": false,
     "start_time": "2023-09-01T16:50:47.015266",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Attention!!!\n",
    "\n",
    "This is a very simple but bad quality notebook. \n",
    " - I do not use any sort of ranking loss, which would be better.\n",
    " - My strategy instead is to min-max scale the times and apply L1-loss\n",
    " - My model is also not optimized. It is a relatively simple GNN that embeds the graph and only processes 1 datapoint at a time and is only trained on 1 epoch.\n",
    " - The public score would be much better if you paired this submission with a trained model for layout. Since this only contributes to half of the score.\n",
    " - Have fun playing around with it!\n",
    " \n",
    " \n",
    " # CHANGES\n",
    " - V5 - normalized train and infer targets, use MSE loss, changed evaluation metric to perform top5 mean instead of top5 max for robustness, 5-fold CV\n",
    " - V6 - use SAGEConv instead of GCN, add dropout layer, increase number of paramters, changed evaluation metric to perform top50 mean, 10->20 epochs.\n",
    " - V13 - fixed problem where model weights weren't being reset leading to heavy overfitting...oops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-output": true,
    "papermill": {
     "duration": 264.245878,
     "end_time": "2023-09-01T16:55:11.276628",
     "exception": false,
     "start_time": "2023-09-01T16:50:47.03075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install torch-geometric torch-scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "papermill": {
     "duration": 4.819384,
     "end_time": "2023-09-01T16:55:16.104784",
     "exception": false,
     "start_time": "2023-09-01T16:55:11.2854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khizbud/miniconda3/envs/latenciaga/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm \n",
    "\n",
    "import sklearn,sklearn.model_selection\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from torch_geometric.nn import GCNConv,SAGEConv\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from timm.scheduler import CosineLRScheduler\n",
    "import matplotlib.pyplot as plt\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/khizbud/predict-ai-model-runtime/predict-ai-model-runtime/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "papermill": {
     "duration": 0.020227,
     "end_time": "2023-09-01T16:55:16.152594",
     "exception": false,
     "start_time": "2023-09-01T16:55:16.132367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_df(directory):\n",
    "    splits = [\"train\", \"valid\", \"test\"]\n",
    "    dfs = dict()\n",
    "    \n",
    "    for split in splits:\n",
    "        path = os.path.join(directory, split)\n",
    "        files = os.listdir(path)\n",
    "        list_df = []\n",
    "        \n",
    "        for file in files:\n",
    "            d = dict(np.load(os.path.join(path,file)))\n",
    "            d['file'] = file\n",
    "            list_df.append(d)\n",
    "        dfs[split] = pd.DataFrame.from_dict(list_df)\n",
    "    return dfs\n",
    "\n",
    "tile_xla = load_df(os.path.join(data_dir, \"npz_all/npz/tile/xla/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'valid', 'test'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tile_xla.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5709"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = tile_xla['train']\n",
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_feat</th>\n",
       "      <th>node_opcode</th>\n",
       "      <th>edge_index</th>\n",
       "      <th>config_feat</th>\n",
       "      <th>config_runtime</th>\n",
       "      <th>config_runtime_normalizers</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[63, 11, 63, 11, 63, 41, 63, 41, 26, 63, 63, 41]</td>\n",
       "      <td>[[1, 0], [3, 2], [5, 1], [5, 4], [7, 3], [7, 6...</td>\n",
       "      <td>[[32.0, 32.0, 0.0, 0.0, 0.0, 0.0, 64.0, 1024.0...</td>\n",
       "      <td>[263238, 2029255, 1192602, 1027600, 1962135, 5...</td>\n",
       "      <td>[263238, 263238, 263238, 263238, 263238, 26323...</td>\n",
       "      <td>alexnet_train_batch_32_-1bae27a41d70f4dc.npz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[24, 13, 48, 87, 63, 13, 25, 52, 25, 63, 24, 1...</td>\n",
       "      <td>[[1, 0], [3, 1], [3, 2], [5, 4], [6, 5], [7, 3...</td>\n",
       "      <td>[[6.0, 12.0, 2.0, 2.0, 0.0, 0.0, 22.0, 288.0, ...</td>\n",
       "      <td>[155012, 3950817, 2048285, 1528077, 682642, 77...</td>\n",
       "      <td>[155012, 155012, 155012, 155012, 155012, 15501...</td>\n",
       "      <td>alexnet_train_batch_32_-21d9f3b8c41eb3e3.npz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[63, 11, 63, 11, 63, 63, 13, 63, 41, 63, 41, 2...</td>\n",
       "      <td>[[1, 0], [3, 2], [6, 5], [8, 1], [8, 7], [10, ...</td>\n",
       "      <td>[[3.0, 12.0, 4.0, 3.0, 0.0, 0.0, 22.0, 432.0, ...</td>\n",
       "      <td>[113020, 667977, 966760, 5897798, 1554171, 308...</td>\n",
       "      <td>[113020, 113020, 113020, 113020, 113020, 11302...</td>\n",
       "      <td>alexnet_train_batch_32_-282ddd3271de7d28.npz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           node_feat  \\\n",
       "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "\n",
       "                                         node_opcode  \\\n",
       "0   [63, 11, 63, 11, 63, 41, 63, 41, 26, 63, 63, 41]   \n",
       "1  [24, 13, 48, 87, 63, 13, 25, 52, 25, 63, 24, 1...   \n",
       "2  [63, 11, 63, 11, 63, 63, 13, 63, 41, 63, 41, 2...   \n",
       "\n",
       "                                          edge_index  \\\n",
       "0  [[1, 0], [3, 2], [5, 1], [5, 4], [7, 3], [7, 6...   \n",
       "1  [[1, 0], [3, 1], [3, 2], [5, 4], [6, 5], [7, 3...   \n",
       "2  [[1, 0], [3, 2], [6, 5], [8, 1], [8, 7], [10, ...   \n",
       "\n",
       "                                         config_feat  \\\n",
       "0  [[32.0, 32.0, 0.0, 0.0, 0.0, 0.0, 64.0, 1024.0...   \n",
       "1  [[6.0, 12.0, 2.0, 2.0, 0.0, 0.0, 22.0, 288.0, ...   \n",
       "2  [[3.0, 12.0, 4.0, 3.0, 0.0, 0.0, 22.0, 432.0, ...   \n",
       "\n",
       "                                      config_runtime  \\\n",
       "0  [263238, 2029255, 1192602, 1027600, 1962135, 5...   \n",
       "1  [155012, 3950817, 2048285, 1528077, 682642, 77...   \n",
       "2  [113020, 667977, 966760, 5897798, 1554171, 308...   \n",
       "\n",
       "                          config_runtime_normalizers  \\\n",
       "0  [263238, 263238, 263238, 263238, 263238, 26323...   \n",
       "1  [155012, 155012, 155012, 155012, 155012, 15501...   \n",
       "2  [113020, 113020, 113020, 113020, 113020, 11302...   \n",
       "\n",
       "                                           file  \n",
       "0  alexnet_train_batch_32_-1bae27a41d70f4dc.npz  \n",
       "1  alexnet_train_batch_32_-21d9f3b8c41eb3e3.npz  \n",
       "2  alexnet_train_batch_32_-282ddd3271de7d28.npz  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['node_feat',\n",
       " 'node_opcode',\n",
       " 'edge_index',\n",
       " 'config_feat',\n",
       " 'config_runtime',\n",
       " 'config_runtime_normalizers',\n",
       " 'file']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_feat <class 'numpy.ndarray'>\n",
      "(12, 140) float32\n",
      "\n",
      "node_opcode <class 'numpy.ndarray'>\n",
      "(12,) uint8\n",
      "\n",
      "edge_index <class 'numpy.ndarray'>\n",
      "(11, 2) int64\n",
      "\n",
      "config_feat <class 'numpy.ndarray'>\n",
      "(266, 24) float32\n",
      "\n",
      "config_runtime <class 'numpy.ndarray'>\n",
      "(266,) int64\n",
      "\n",
      "config_runtime_normalizers <class 'numpy.ndarray'>\n",
      "(266,) int64\n",
      "\n",
      "file <class 'str'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k, v in train_df.iloc[0].to_dict().items():\n",
    "    print(k, type(v))\n",
    "    if isinstance(v, np.ndarray):\n",
    "        print(v.shape, v.dtype)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008874,
     "end_time": "2023-09-01T16:56:21.968592",
     "exception": false,
     "start_time": "2023-09-01T16:56:21.959718",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define Dataset and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "papermill": {
     "duration": 0.020329,
     "end_time": "2023-09-01T16:56:21.997734",
     "exception": false,
     "start_time": "2023-09-01T16:56:21.977405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TileDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        config_feat = torch.tensor(row['config_feat'].astype(np.float32))\n",
    "        node_feat = torch.tensor(row['node_feat'].astype(np.float32))\n",
    "        node_opcode = torch.tensor(row['node_opcode'].astype(np.int64))\n",
    "        edge_index = torch.tensor(np.swapaxes(row['edge_index'],0,1).astype(np.int64))\n",
    "        target = (row['config_runtime']/(row['config_runtime_normalizers']+1e-5)).astype(np.float32) #/row['config_runtime_normalizers']\n",
    "        # minmax scale the target, we only care about order\n",
    "        target = (target-np.mean(target))/(np.std(target)+1e-5)\n",
    "\n",
    "#         target = (target-np.mean(target))/(np.std(target))\n",
    "        target = torch.tensor(target)\n",
    "        return config_feat,node_feat,node_opcode,edge_index,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "                 hidden_channels = [32,48,64,84], \n",
    "                 graph_in = 64, \n",
    "                 graph_out = 64, \n",
    "                 hidden_dim=128, \n",
    "                 dropout = 0.2):\n",
    "        super().__init__()\n",
    "        op_embedding_dim = 4 # I choose 4-dimensional embedding\n",
    "        self.embedding = torch.nn.Embedding(120, #120 different op-codes\n",
    "                                            op_embedding_dim,\n",
    "                                           )\n",
    "        assert len(hidden_channels)>0\n",
    "        \n",
    "        self.linear = nn.Linear(op_embedding_dim+140,graph_in)\n",
    "        in_channels=graph_in\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        last_dim = hidden_channels[0]\n",
    "        conv = SAGEConv\n",
    "        self.convs.append(conv(in_channels, hidden_channels[0]))\n",
    "        for i in range(len(hidden_channels)-1):\n",
    "            self.convs.append(conv(hidden_channels[i], hidden_channels[i+1]))\n",
    "            last_dim = hidden_channels[i+1]\n",
    "        self.convs.append(conv(last_dim, graph_out))\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.dense = torch.nn.Sequential(nn.Linear(graph_out*2+24, hidden_dim),\n",
    "                                         nn.Dropout(p=dropout),\n",
    "                                         nn.ReLU(),\n",
    "                                         nn.Linear(hidden_dim, hidden_dim),\n",
    "                                         nn.Dropout(p=dropout),\n",
    "                                         nn.ReLU(),\n",
    "                                         nn.Linear(hidden_dim, 1),\n",
    "                                        )\n",
    "#         self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x_cfg: Tensor,x_feat: Tensor, x_op: Tensor, edge_index: Tensor) -> Tensor:\n",
    "        \n",
    "        #get graph features\n",
    "        x = torch.concat([x_feat,self.embedding(x_op)],dim = 1)\n",
    "        x = self.linear(x)\n",
    "        #pass though conv layers\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index).relu()\n",
    "        # get 1d graph embedding using average pooling\n",
    "        x_mean = x.mean(0)\n",
    "        x_max = x.max(0).values\n",
    "        \n",
    "        #put graph data into config data\n",
    "        x = torch.concat([x_cfg,x_max.repeat((len(x_cfg),1)),x_mean.repeat((len(x_cfg),1))],axis=1)\n",
    "        #put into dense nn\n",
    "        x = torch.flatten(self.dense(x))\n",
    "        x = (x-torch.mean(x))/(torch.std(x)+1e-5)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008439,
     "end_time": "2023-09-01T16:56:22.088164",
     "exception": false,
     "start_time": "2023-09-01T16:56:22.079725",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train One Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "papermill": {
     "duration": 0.021726,
     "end_time": "2023-09-01T16:56:22.11899",
     "exception": false,
     "start_time": "2023-09-01T16:56:22.097264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.concat((tile_xla[\"train\"],tile_xla[\"valid\"]),axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "papermill": {
     "duration": 9138.052878,
     "end_time": "2023-09-01T19:28:40.180685",
     "exception": false,
     "start_time": "2023-09-01T16:56:22.127807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 epoch 0, comp_score = 0.614, mean_score = 0.289,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                        \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m out \u001b[38;5;241m=\u001b[39m model(cfg_ft,nd_ft,nd_op,ind)\n\u001b[1;32m     44\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(out, target)\n\u001b[0;32m---> 45\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1e-2\u001b[39m)\n\u001b[1;32m     47\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_dataset)\u001b[38;5;241m*\u001b[39mepoch)\n",
      "File \u001b[0;32m~/miniconda3/envs/latenciaga/lib/python3.9/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/latenciaga/lib/python3.9/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kfold = sklearn.model_selection.KFold(n_splits=5,shuffle=True,random_state=0)\n",
    "score_means = []\n",
    "score_maxs = []\n",
    "for fold,(tr_idx,va_idx) in enumerate(kfold.split(df)):\n",
    "    model = SimpleModel().to(device)\n",
    "    train_dataset = TileDataset(df.iloc[tr_idx])\n",
    "    val_dataset = TileDataset(df.iloc[va_idx])\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    steps = len(train_dataset)*20\n",
    "    warmup_steps = int(steps*0.2)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4,weight_decay = 1e-4)\n",
    "    scheduler = CosineLRScheduler(optimizer,t_initial= steps,warmup_t=warmup_steps, warmup_lr_init=1e-6,lr_min=2e-8,)\n",
    "    \n",
    "    def score_tile_mean(predictions, df):\n",
    "        score = 0\n",
    "        for i in range(len(df)):\n",
    "            predbest = np.mean(df.iloc[i]['config_runtime'][predictions[i]])\n",
    "            best = np.mean(np.sort(df.iloc[i]['config_runtime'])[:50])\n",
    "            score += 2-predbest/best\n",
    "        score /= len(df)\n",
    "        return score\n",
    "    def score_tile_max(predictions, df):\n",
    "        score = 0\n",
    "        for i in range(len(df)):\n",
    "            predbest = np.min(df.iloc[i]['config_runtime'][predictions[i][:5]])\n",
    "            best = np.min(df.iloc[i]['config_runtime'])\n",
    "    #         print(best,predbest)\n",
    "            score += 2 - predbest/best\n",
    "        score /= len(df)\n",
    "        return score\n",
    "\n",
    "    best_score = 0\n",
    "    best_score_max = 0\n",
    "    for epoch in range(10):\n",
    "        model.train()\n",
    "        pbar = tqdm(range(len(train_dataset)),leave=False)\n",
    "        loss_sum = 0\n",
    "        n = 0\n",
    "        for i in pbar:\n",
    "            cfg_ft,nd_ft,nd_op,ind,target = train_dataset[i]\n",
    "            cfg_ft,nd_ft,nd_op,ind,target = cfg_ft.to(device),nd_ft.to(device),nd_op.to(device),ind.to(device),target.to(device)\n",
    "\n",
    "            out = model(cfg_ft,nd_ft,nd_op,ind)\n",
    "            loss = criterion(out, target)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1e-2)\n",
    "            scheduler.step(i+len(train_dataset)*epoch)\n",
    "            optimizer.step()\n",
    "            loss_sum+=loss.item()\n",
    "            n+=1\n",
    "            pbar.set_description(f'running loss: {(loss_sum/n):.2f},current loss: {(loss.item()):.2f}')\n",
    "        pbar.close()\n",
    "        model.eval()\n",
    "\n",
    "        tile_xla_predictions = []\n",
    "        pbar = tqdm(range(len(val_dataset)),leave=False)\n",
    "        for i in pbar:\n",
    "            cfg_ft,nd_ft,nd_op,ind,target = val_dataset[i]\n",
    "            cfg_ft,nd_ft,nd_op,ind,target = cfg_ft.to(device),nd_ft.to(device),nd_op.to(device),ind.to(device),target.to(device)\n",
    "\n",
    "            out = model(cfg_ft,nd_ft,nd_op,ind)\n",
    "            tile_xla_predictions.append(np.argsort(out.detach().cpu().numpy())[:50])\n",
    "        pbar.close()\n",
    "        score_mean = score_tile_mean(tile_xla_predictions, val_dataset.df)\n",
    "        score_max = score_tile_max(tile_xla_predictions, val_dataset.df)\n",
    "        print(f'fold {fold} epoch {epoch}, comp_score = {score_max:.3f}, mean_score = {score_mean:.3f},')\n",
    "        if score_mean>best_score:\n",
    "            best_score = score_mean\n",
    "            best_score_max = score_max\n",
    "            torch.save(model.state_dict(), f'best_model_{fold}.pth')\n",
    "    score_means.append(best_score)\n",
    "    score_maxs.append(best_score_max)\n",
    "print(f'comp_score = {np.mean(score_maxs)}, mean_score = {np.mean(score_means)},')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 20.903162,
     "end_time": "2023-09-01T19:29:21.465429",
     "exception": false,
     "start_time": "2023-09-01T19:29:00.562267",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Evaluate on Validation Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 20.540632,
     "end_time": "2023-09-01T19:30:02.340577",
     "exception": false,
     "start_time": "2023-09-01T19:29:41.799945",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**0.31 is not bad considering that this model only trained on 1 epoch and is not on a ranking loss!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 20.552961,
     "end_time": "2023-09-01T19:30:43.664106",
     "exception": false,
     "start_time": "2023-09-01T19:30:23.111145",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Predict and Submit (only tile:xla predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "papermill": {
     "duration": 42.864288,
     "end_time": "2023-09-01T19:31:46.765649",
     "exception": false,
     "start_time": "2023-09-01T19:31:03.901361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 844/844 [00:07<00:00, 112.90it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 844/844 [00:14<00:00, 57.25it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 844/844 [00:07<00:00, 107.40it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 844/844 [00:06<00:00, 126.68it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 844/844 [00:09<00:00, 85.39it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = TileDataset(tile_xla[\"test\"])\n",
    "tile_xla_predictions = [[] for i in range(len(dataset))]\n",
    "for fold in range(5):\n",
    "    model.load_state_dict(torch.load(f'best_model_{fold}.pth', map_location=device))\n",
    "    model.eval()\n",
    "    pbar = tqdm(range(len(dataset)))\n",
    "    for i in pbar:\n",
    "        cfg_ft,nd_ft,nd_op,ind,target = dataset[i]\n",
    "        cfg_ft,nd_ft,nd_op,ind,target = cfg_ft.to(device),nd_ft.to(device),nd_op.to(device),ind.to(device),target.to(device)\n",
    "\n",
    "        out = model(cfg_ft,nd_ft,nd_op,ind)\n",
    "        tile_xla_predictions[i].append(out.detach().numpy())\n",
    "tile_xla_predictions = [np.argsort(np.mean(pred,axis=0))[:5] for pred in tile_xla_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "papermill": {
     "duration": 20.880172,
     "end_time": "2023-09-01T19:32:28.307392",
     "exception": false,
     "start_time": "2023-09-01T19:32:07.42722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TopConfigs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tile:xla:d6f5f54247bd1e58a10b9e7062c636ab</td>\n",
       "      <td>0;1;2;3;4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tile:xla:e3a655daa38e34ec240df959b650ac16</td>\n",
       "      <td>827;125;1065;709;281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tile:xla:f8c2c1a1098b2a361c26df668b286c87</td>\n",
       "      <td>41;116;101;202;166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tile:xla:4dd1716853ed46ee4e7d09ede1732de8</td>\n",
       "      <td>1474;1045;5985;6222;4859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tile:xla:d0a69155b6340748c36724e4bfc34be3</td>\n",
       "      <td>655;159;650;151;215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>layout:nlp:random:60880ed76de53f4d7a1b960b24f2...</td>\n",
       "      <td>0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>layout:nlp:random:23559853d9702baaaacbb0c83fd3...</td>\n",
       "      <td>0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>layout:nlp:random:f6c146fc5cf10be4f3accbaca989...</td>\n",
       "      <td>0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>layout:nlp:random:32531d07a084b319dce484f53a4c...</td>\n",
       "      <td>0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>layout:nlp:random:3a0c5517a87df8d82fd637b83298...</td>\n",
       "      <td>0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>894 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    ID  \\\n",
       "0            tile:xla:d6f5f54247bd1e58a10b9e7062c636ab   \n",
       "1            tile:xla:e3a655daa38e34ec240df959b650ac16   \n",
       "2            tile:xla:f8c2c1a1098b2a361c26df668b286c87   \n",
       "3            tile:xla:4dd1716853ed46ee4e7d09ede1732de8   \n",
       "4            tile:xla:d0a69155b6340748c36724e4bfc34be3   \n",
       "..                                                 ...   \n",
       "889  layout:nlp:random:60880ed76de53f4d7a1b960b24f2...   \n",
       "890  layout:nlp:random:23559853d9702baaaacbb0c83fd3...   \n",
       "891  layout:nlp:random:f6c146fc5cf10be4f3accbaca989...   \n",
       "892  layout:nlp:random:32531d07a084b319dce484f53a4c...   \n",
       "893  layout:nlp:random:3a0c5517a87df8d82fd637b83298...   \n",
       "\n",
       "                                            TopConfigs  \n",
       "0                                            0;1;2;3;4  \n",
       "1                                 827;125;1065;709;281  \n",
       "2                                   41;116;101;202;166  \n",
       "3                             1474;1045;5985;6222;4859  \n",
       "4                                  655;159;650;151;215  \n",
       "..                                                 ...  \n",
       "889  0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...  \n",
       "890  0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...  \n",
       "891  0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...  \n",
       "892  0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...  \n",
       "893  0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...  \n",
       "\n",
       "[894 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv(os.path.join(data_dir, 'sample_submission.csv'))\n",
    "for i,filename in enumerate(tile_xla[\"test\"]['file'].values):\n",
    "    id = 'tile:xla:' +filename[:-4]\n",
    "    sub.loc[sub.ID == id,'TopConfigs'] = ';'.join(tile_xla_predictions[i].astype(str))\n",
    "sub.to_csv('submission.csv',index=False)\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9735.485807,
   "end_time": "2023-09-01T19:32:52.176348",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-09-01T16:50:36.690541",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
